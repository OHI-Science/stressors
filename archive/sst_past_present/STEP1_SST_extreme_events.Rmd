---
title: 'Sea Surface Temperature Pressure Layer'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: false
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '../../../workflow/templates/ohi_hdr.html'
  pdf_document:
    toc: true
---


# Summary

This script creates the Sea Surface Temperature (SST) stressor.


***  

# Data Source

Data comes from [CoRTAD version 6](https://www.ncei.noaa.gov/products/coral-reef-temperature-anomaly-database)
[and](https://www.ncei.noaa.gov/data/oceans/cortad/Version6/)


**Native Data Resolution**: ~4km   
**Description**: 
Cortadv6_SSTA.nc = SST anomalies (weekly SST minus weekly climatological SST), weekly data for all years, degrees Kelvin
Cortadv6_weeklySST.nc =  SST, weekly data for all years, degrees Kelvin  
**Time Range**: 1982 - 2020 (weekly averages across all years)  
**Format**: NetCDF
**Downloaded**: September 8, 2021

***  

# Methods

1. Extreme events per year based calculated as number of times SST anomaly exceeds the 90th quantile calculated from SST based on weekly values from 1985-2015.
2. Sum extreme weekly events for each year. Final file ends up using summing extreme events from 2016-2020.
3. Rescale by dividing by the total possible extreme events in a 5 year period.

## Setup

```{r setup, message=F,warning=F, eval = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'figs/', message = FALSE, warning = FALSE)

library(raster)
library(RColorBrewer)
library(tidyverse)
library(rgdal)
library(doParallel)
library(foreach)
library(sf)
library(ncdf4)
library(httr)
library(lubridate)
library(animation)
library(ggplot2)
library(plotly)
library(here)


dir_M <- file.path("/home/shares/ohi")

yrs <- 1982:2020
ref_years <-c(1985:1989)

cols <- rev(colorRampPalette(brewer.pal(11, 'Spectral'))(255)) # rainbow color scheme

mollCRS=raster::crs('+proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs')

template_raster <- raster(here("spatial/output/template_raster.tif"))

rasterOptions(maxmemory= 50e+09, chunksize=10e+08, progress = 'text', timer=TRUE)  

```

***

## Get new data if available

```{r get new data, eval = FALSE}

## download URL
url <- "https://data.nodc.noaa.gov/cortad/Version6"

## retrieve the netcdf data, SSTA (~98GB) and WeeklySST (~28GB)
## these take like 2 hours, it's a lot of data!!!
ssta <- sprintf("%s/cortadv6_SSTA.nc", url)
ssta_filename <- file.path(dir_M, "stressors_2021/_raw_data/SST_cortad/cortadv6_SSTA.nc")
ssta_res <- httr::GET(ssta, write_disk(ssta_filename))

weekly_sst <- sprintf("%s/cortadv6_FilledSST.nc", url)
weekly_sst_filename <- file.path(dir_M, "stressors_2021/_raw_data/SST_cortad/cortadv6_FilledSST.nc")
weekly_sst_res <- httr::GET(weekly_sst, write_disk(weekly_sst_filename))

closeAllConnections()
```

***

## Generate annual extreme events

We define an extreme event as time when the average weekly anomoly temperature exceeds the 90th quantile calculated for years 1985-2015 for each week of the year (1 through ~52). For each raster cell, we count the number of weeks this is exceeded for each year from 2016-2020, so values can range from 0-52. To smooth for yearly stochasticity we then sum the exceedences for the 5 year period from 2016-2020. 

## Get list of data
```{r generate annual positive anomalies, eval = FALSE}
## load netcdf sst data
ssta         <- stack(list.files(file.path(dir_M, "stressors_2021/_raw_data/SST_cortad"), pattern = "SSTA.nc",
                                 full.names = TRUE), varname = "SSTA")
weekly_sst   <- stack(list.files(file.path(dir_M, "stressors_2021/_raw_data/SST_cortad"), pattern = "FilledSST.nc",
                                 full.names = TRUE), varname = "FilledSST")

names_ssta   <- names(ssta)
names_weekly <- names(weekly_sst)

ssta_df <- names_ssta %>% # View(ssta_df)
  data.frame() %>% 
  rename(name = ".") %>% 
  mutate(year = substr(name, 2, 5), 
         month = substr(name, 7, 8), 
         day = substr(name, 10, 11)) %>% 
  mutate(week = week(as.Date(sprintf("%s-%s-%s", year, month, day))))

```


# Calculate weekly 90th quantile, using 1985 - 2015

```{r}


yrs <- 1985:2015

for(week in 1:53){
  
 # week = 1
  t0 = Sys.time()
  print(paste("calculating 90th quantile for week", week, "-- started at", t0))

    s = stack()
  for (yr in yrs){ # yr = 1999
    # FOR APPROACH OF USING REF PERIOD TO CALC EXTREME EVENTS: CHANGE 'YRS' HERE TO INCLUDE JUST REFERENCE YEARS
    w = which(substr(names_weekly, 2, 5) == yr)[week]
    if(is.na(week)) next() # most yrs don't have 53 weeks; 'next' works in for loop but not foreach+dopar
    w_week = ssta[[w]]
    s = stack(s, w_week)
  }
  
## memory requirements
    # https://strimas.com/post/processing-large-rasters-in-r/
# mem_est <-  8 * ncell(s)*nlayers(s) / 2^20  #11,106 MB to hold object
#  canProcessInMemory(s, verbose=TRUE)  
#  rasterOptions()
#  blockSize(s)
  
rasterOptions(maxmemory= 50e+09, chunksize=10e+08)  

fun_90 <- function(x){quantile(x, probs = c(0.90), na.rm=TRUE)}

beginCluster(n=8)
quant_raster <- raster::clusterR(s, fun = calc, args=list(fun=fun_90))
endCluster()

#plot(quant_raster)
#test <- quant_raster
# test[test>7] <- 7 
# plot(test)

writeRaster(quant_raster, file.path(dir_M, sprintf("stressors_2021/_dataprep/SST_past_present/anomoly_90quant_1985-2015/quant_ref_anomoly_week_%s.tif", week)), overwrite=TRUE)

}

```

### calculate exceedences for years 2016 - 2020

```{r}
 yrs <- 2016:2020

## calculate annual positive anomalies; ~17 minutes per year with 5 cores
for(yr in yrs){ # yr=yrs[2]
    t0 = Sys.time()
  print(paste("calculating anomaly for", yr, "-- started at", t0))

for(week in 1:52){ # week = wks$week[1]
    quant_sst = raster::raster(file.path(dir_M, sprintf( "stressors_2021/_dataprep/SST_past_present/anomoly_90quant_1985-2015/quant_ref_anomoly_week_%s.tif", week))) 
    w = which(substr(names_ssta, 2, 5) == yr)[week]
    w_ssta = ssta[[w]]
    
    fun_exceed <- function(x, y){ifelse(is.na(x) | is.na(y), 0, ifelse(x > y, 1, 0))}
    
    beginCluster(n=8)
    weekly_exceed <- raster::clusterR(stack(w_ssta, quant_sst),
                     overlay, 
                    arg = list(fun = fun_exceed))
    endCluster()

  writeRaster(weekly_exceed, filename = file.path(dir_M, sprintf("stressors_2021/_dataprep/SST_past_present/weekly_quant_exceed/quant_exceed_%s_%s.tif", week, yr)), overwrite=TRUE)
  }
}
  

```

## Calculate quantile annual exceedances
Sum proportion of weekly exceedences in each year. 
```{r}
 yrs <- 2016:2020
for(yr in yrs){  # yr = yrs[2]

  yearly_files <- list.files(file.path(dir_M, sprintf("stressors_2021/_dataprep/SST_past_present/weekly_quant_exceed")), pattern=sprintf("_%s.tif", yr), full=TRUE)
  
  yearly_files_stack <- stack(yearly_files)

  t0 <- Sys.time()
    test <- calc(yearly_files_stack, fun = sum, na.rm=TRUE)
    test <- test/52
    writeRaster(test, filename = file.path(dir_M, sprintf("stressors_2021/_dataprep/SST_past_present/annual_quant_exceed/annual_quant_exceed_%s.tif", yr)), overwrite=TRUE)
    
  Sys.time() - t0
  
}

yr <- 2020
tmp <- raster(file.path(dir_M, sprintf("stressors_2021/_dataprep/SST_past_present/annual_quant_exceed/annual_quant_exceed_%s.tif", yr)))
plot(tmp, main = yr)

```
  

## calculate average exceedences for 5 years

* Average of 5 year intervals of weekly proportional exceedences (e.g. sum of exceedences divided by 52)
* Convert to mollweide
* Aggregate to be closer to our target raster resolution
* Resample to have same dimensions as target raster
* Mask ocean
* Save
```{r cumulative sum of extreme events, eval = FALSE}

exceed_files <- list.files(file.path(dir_M, sprintf("stressors_2021/_dataprep/SST_past_present/annual_quant_exceed/", pattern = "annual_quant_exceed")), full.names = TRUE)

yrs <- 2016:2020
#registerDoParallel(3)
#t0 = Sys.time()
#foreach(year = seq(2016, max(yrs)-4)) %dopar% { # year = 2016
  years = year:(year + 4) 
  
stack_exceed <- stack(exceed_files[substr(exceed_files, 101, 104) %in% years]) %>% 
  mean(.)

projection(stack_exceed) = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
  
tmp_mol <-  projectRaster(stack_exceed, crs = mollCRS, over = TRUE) 
tmp_mol <- aggregate(tmp_mol, fact=2, fun=mean) # get close to resolution of template raster, not sure if this is necessary, but makes me feel better.
tmp_mol <- resample(tmp_mol, template_raster, method="bilinear")

## gapfill
gf_raster <- function(x){raster::focal(x, w = matrix(1,3,3), fun = mean, na.rm=TRUE, pad = TRUE, NAonly=TRUE)}

ocean_template <- raster("../spp_vuln_mapping/_spatial/ocean_area_mol.tif")
ocean_template[ocean_template>0] <- 1

r = tmp_mol
  
## Repeat 100 times (most is immediately gapfilled but the antarctic area was persistent)
i <- 0
while (i <= 100){
r <- gf_raster(r)
i <- i + 1
print(i)
}

r <- r*ocean_template

writeRaster(r, filename = file.path(dir_M, sprintf("stressors_2021/_dataprep/SST_past_present/final_extreme/sst_exceeds_90quant_%s-%s.tif", 
                                   yrs[1], yrs[5])), overwrite = TRUE)


```


## Check to see if we need to gapfill

```{r}

diffs <- list.files(file.path(dir_M, "stressors_2021/_dataprep/SST_past_present/change_in_exceed"), pattern = "compared", full.names = TRUE)
org_data <- raster(diffs[[1]])
#org_data <- r # use this option to test gapfilling below
plot(org_data)

ocean_template <- raster("../spp_vuln_mapping/_spatial/ocean_area_mol.tif")
ocean_template[ocean_template>0] <- 1
plot(ocean_template)

org_data[!is.na(org_data)] <- 1
plot(org_data)

org_data[is.na(org_data)] <- 0
ocean_template[is.na(ocean_template)] <- 0

need_gf <- ocean_template - org_data
need_gf[need_gf==0] <- NA
need_gf[need_gf==-1] <- NA

plot(need_gf)

plot(raster(diffs[[1]]))
plot(need_gf, add=TRUE, col="red")

```


## Get mean SST data for select years

```{r}

weekly_sst   <- stack(list.files(file.path(dir_M, "stressors_2021/_raw_data/SST_cortad"), pattern = "FilledSST.nc",
                                 full.names = TRUE), varname = "FilledSST")

plot(weekly_sst[[1]])

rasterOptions(progress = 'text',timer=TRUE)

yrs <- 2016:2020


registerDoParallel(5)

foreach(year = yrs) %dopar%{ # year <- 2020

year_sst <- weekly_sst[[grep(year, names(weekly_sst))]] 

test <- raster::calc(year_sst, fun = mean, na.rm=TRUE)

raster::writeRaster(test, filename = file.path(dir_M, sprintf("stressors_2021/_dataprep/SST_past_present/annual_SST/annual_sst_%s.tif", year)), overwrite=TRUE, progress="text") 
}


#stopCluster()
  



```

## calculate average SST for 2016-2020

* Average of SST from 2016-2020 
* Convert to mollweide
* Aggregate to be closer to our target raster resolution
* Resample to have same dimensions as target raster
* Mask ocean
* Save
```{r cumulative sum of extreme events, eval = FALSE}

yrs <- 2016:2020

sst_yearly <- list.files(file.path(dir_M, "stressors_2021/_dataprep/SST_past_present/annual_SST"), full=TRUE)
sst_yearly <- grep(paste(yrs, collapse="|"), sst_yearly, value=TRUE)

sst_avg <- stack(sst_yearly) %>% 
  mean(.) 

sst_avg_c <- sst_avg - 273 # convert to C from K

projection(sst_avg_c) = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
  
sst_avg_mol <-  projectRaster(sst_avg_c, crs = mollCRS, over = TRUE) 
sst_avg_mol <- aggregate(sst_avg_mol, fact=2, fun=mean) # get close to resolution of template raster, not sure if this is necessary, but makes me feel better.
sst_avg_mol <- resample(sst_avg_mol, template_raster, method="bilinear")

## gapfill
gf_raster <- function(x){raster::focal(x, w = matrix(1,3,3), fun = mean, na.rm=TRUE, pad = TRUE, NAonly=TRUE)}

ocean_template <- raster("../spp_vuln_mapping/_spatial/ocean_area_mol.tif")
ocean_template[ocean_template>0] <- 1

r = sst_avg_mol
  
## Repeat 100 times (most is immediately gapfilled but the antarctic area was persistent)
i <- 0
while (i <= 100){
r <- gf_raster(r)
i <- i + 1
print(i)
}

r <- r*ocean_template

writeRaster(r, filename = file.path(dir_M, sprintf("stressors_2021/_dataprep/SST_past_present/final_avg_tmp/sst_avg_%s-%s.tif", 
                                   yrs[1], yrs[5])), overwrite = TRUE)

plot(raster(list.files(file.path(dir_M, "stressors_2021/_dataprep/SST_past_present/final_avg_tmp"), full=TRUE)[1]))

```

## Function to turn to rescaled stressor specific to each taxa

```{r}

T_max_a <- 25
T_max_p <- 20
T_raster <- raster(list.files(file.path(dir_M, "stressors_2021/_dataprep/SST_past_present/final_avg_tmp"), full=TRUE)[1])

T_max_pressure <- function(T_max_a, T_max_p, T_raster){
#t0 <- Sys.time()
pressure <- (1/(T_max_a - T_max_p))*(T_raster-T_max_p)
pressure[pressure<0] <- 0
pressure[pressure>1] <- 1
return(pressure)
#Sys.time()-t0
}

t0 <- Sys.time()
tmp <- T_max_pressure(T_max_a = T_max_a, T_max_p = T_max_p, T_raster=T_raster)
Sys.time()-t0

```

# Citation information  

Selig, E.R., K.S. Casey, and J.F. Bruno (2010), New insights into global patterns of ocean temperature anomalies: implications for coral reef health and management, Global Ecology and Biogeography, DOI: 10.1111/j.1466-8238.2009.00522.x.
